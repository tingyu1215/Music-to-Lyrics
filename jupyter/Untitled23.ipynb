{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-06f582e60de6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#import tensorflow as tf ;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#import genism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m \u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m \u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhrases\u001b[0m \u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# need a pretrain model\n",
    "# maybe the code is on tf1\n",
    "# https://radimrehurek.com/gensim/models/word2vec.html\n",
    "#import tensorflow as tf ;\n",
    "#import genism\n",
    "from gensim.models import Word2Vec ;\n",
    "from gensim.models import KeyedVectors ;\n",
    "from gensim.models import Phrases ;\n",
    "import gensim.downloader as dataset_list\n",
    "import numpy ;\n",
    "from gensim import utils\n",
    "import os ;\n",
    "\n",
    "\n",
    "#pretrained_model = dataset_list.load('glove-twitter-25')\n",
    "#not an full model\n",
    "# just an 2d array, so wv[] is allowed\n",
    "# cosine similarity\n",
    "#print(pretrained_vectors.most_similar('minecraft')) ;\n",
    "\n",
    "\n",
    "\n",
    "#forward_text = numpy.load('') ;\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_fileplace = os.getcwd()+'\\\\Sentence_and_Word_Parsing' ;\n",
    "        for file_name in os.listdir(corpus_fileplace) :\n",
    "            #print(file_name) ;\n",
    "            if file_name == 'desktop.ini' : break ;\n",
    "            files = numpy.load(corpus_fileplace+'\\\\'+file_name,allow_pickle=True) ;\n",
    "            #print(files[0][2])\n",
    "            combine = [] ;\n",
    "            for senetence in files[0][2] :\n",
    "                #print(senetence)\n",
    "                for word_len in senetence :\n",
    "                    #print(type(word_list))\n",
    "                    #print(word_len[0])\n",
    "                    combine.append(word_len[0]) ;\n",
    "                    #combine += \" \" ;\n",
    "                #print(combine)\n",
    "                #yield \" \".join(combine) ;\n",
    "                yield combine ;\n",
    "\n",
    "model = Word2Vec(sentences=MyCorpus() ,size= 100, window= 5 ,min_count= 1, workers= 8)\n",
    "# it can access iterator !!!\n",
    "print(\"I'm fine\") ;\n",
    "'''\n",
    "for sentence in iter(MyCorpus()) :\n",
    "    combine = [] ;\n",
    "    print(sentence) ;\n",
    "    for word_list in sentence :\n",
    "        combine += word_list ;\n",
    "    model.build_vocab(\" \".join(combine),update=False) ;\n",
    "    model.train(\" \".join(combine)) ;\n",
    "'''\n",
    "\n",
    "model.save(\"finishw2v.model\")\n",
    "#model = Word2Vec.load(\"w2v.model\") ;\n",
    "\n",
    "\n",
    "'''\n",
    "model.train([[test,foo,bar]], total_examples= 1, epochs= 1) # put our dataset there\n",
    "#The trained word vectors are stored in a KeyedVectors instance\n",
    "#that can make it faster (smaller)\n",
    "vector = model.wv[\"computer\"] ;\n",
    "word_vectors = model.mv ;\n",
    "print(model.mv) ;\n",
    "word_vectors.save(\"w2v.wordvectors\",mmap=\"r\") ;\n",
    "vector = wv[\"computer\"] ;\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
